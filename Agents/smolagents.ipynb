{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzlMaKBy9NXI"
      },
      "outputs": [],
      "source": [
        "!pip install -q huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gw7yUDjI1hOQ"
      },
      "outputs": [],
      "source": [
        "!pip install smolagents\n",
        "!pip install ddgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MkbPF7A2RbS"
      },
      "outputs": [],
      "source": [
        "from smolagents import CodeAgent, DuckDuckGoSearchTool, InferenceClientModel\n",
        "from smolagents import tool\n",
        "from huggingface_hub import list_models\n",
        "\n",
        "\n",
        "\n",
        "@tool\n",
        "def my_custom_tool(task: str) -> str:\n",
        "    \"\"\"\n",
        "    Returns the most downloaded model of a given task from Hugging Face Hub.\n",
        "    Args:\n",
        "        task: The task name (e.g., \"text-generation\")\n",
        "    \"\"\"\n",
        "    most_downloaded = next(list_models(filter=task, sort=\"downloads\", direction=-1))\n",
        "    return most_downloaded.id\n",
        "\n",
        "\n",
        "model = InferenceClientModel(model_id=\"Qwen/Qwen3-4B-Thinking-2507\")\n",
        "agent=CodeAgent(tools=[my_custom_tool],model=model)\n",
        "\n",
        "# Create the agent with the search tool\n",
        "# agent = CodeAgent(\n",
        "#     tools=[DuckDuckGoSearchTool()],\n",
        "#     model=model,\n",
        "# )\n",
        "\n",
        "# # Run the agent with your query\n",
        "# result = agent.run(\"Who was 1st president of India?\")\n",
        "# print(result)\n",
        "result = agent.run(\"Get the most downloaded model for text-generation\")\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_kV48kvS959"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['HF_TOKEN'] =userdata.get('HF_TOKEN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BC633VsJ9mwi"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# from smolagents import CodeAgent, DuckDuckGoSearchTool, InferenceClientModel\n",
        "# model = InferenceClientModel(model_id=\"Qwen/Qwen3-4B-Thinking-2507\")\n",
        "# agent = CodeAgent(\n",
        "#     model=model,\n",
        "#     tools=[DuckDuckGoSearchTool()],\n",
        "# )\n",
        "\n",
        "# agent.run(\"How many seconds does clock take to complete one minute?\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRvrKsM9YwL0"
      },
      "outputs": [],
      "source": [
        "pip install google-generativeai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKoRYRSxZST3"
      },
      "outputs": [],
      "source": [
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "response = model.generate_content(\"Write a short poem about AI and coffee\")\n",
        "print(response.text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcyeaTy_U_Vj"
      },
      "outputs": [],
      "source": [
        "# agent.run('What is the cube root of 64?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3SL5GCPW2BR"
      },
      "outputs": [],
      "source": [
        "pip install litellm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QM8GoUIQvXaQ"
      },
      "outputs": [],
      "source": [
        "from smolagents import CodeAgent, DuckDuckGoSearchTool, LiteLLMModel\n",
        "\n",
        "# Pass your Gemini API key (set it as env variable for safety!)\n",
        "import os\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"your_api_key_here\"\n",
        "\n",
        "# LiteLLM uses gemini models with the provider prefix \"gemini\"\n",
        "model = LiteLLMModel(model_id=\"gemini/gemini-1.5-flash\", api_key=api_key)\n",
        "\n",
        "agent = CodeAgent(\n",
        "    tools=[DuckDuckGoSearchTool()],\n",
        "    model=model\n",
        ")\n",
        "\n",
        "result = agent.run(\"Search for the best music recommendations for a party at a mansion.\")\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1es_p4-HdhX"
      },
      "source": [
        "Using ToolAgent instead of CodeAgent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEac26JYGTwG"
      },
      "outputs": [],
      "source": [
        "from smolagents import ToolCallingAgent, DuckDuckGoSearchTool, LiteLLMModel\n",
        "from typing import Optional\n",
        "model=LiteLLMModel(model_id=\"gemini/gemini-1.5-flash\", api_key=api_key)\n",
        "agent = ToolCallingAgent(\n",
        "    tools=[DuckDuckGoSearchTool()],\n",
        "    model=model\n",
        ")\n",
        "@tool\n",
        "def get_weather(location:str,celsius:Optional[bool]=False)->str:\n",
        "    \"\"\"\n",
        "    Get weather of the location at present and upcoming days.\n",
        "    Args:\n",
        "        location : the location\n",
        "        celsius : whether to use celsius for temperature\n",
        "    \"\"\"\n",
        "    return f\"the weather in {location} is sunny with low temperatures. \\n\"\n",
        "\n",
        "# agent=ToolCallingAgent(tools=[get_weather],model=model)\n",
        "result = agent.run(\"What's the weather in New York ?\")\n",
        "print(result)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYNnYQH3McGo"
      },
      "outputs": [],
      "source": [
        "!pip install gradio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IX34kqetOwgV"
      },
      "source": [
        "Gradio use to generate image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkxeL3UKMhdR"
      },
      "outputs": [],
      "source": [
        "from smolagents import ToolCallingAgent,load_tool, DuckDuckGoSearchTool, LiteLLMModel,GradioUI\n",
        "image_generation_tool=load_tool(\"m-ric/text-to-image\",trust_remote_code=True)\n",
        "model=LiteLLMModel(model_id=\"gemini/gemini-1.5-flash\", api_key=api_key)\n",
        "agent = ToolCallingAgent(\n",
        "    tools=[DuckDuckGoSearchTool(),image_generation_tool],\n",
        "    model=model\n",
        ")\n",
        "GradioUI(agent).launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZNv20La045k"
      },
      "source": [
        "Using Jina AI for web scrapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7T8P0UIZzh0l"
      },
      "outputs": [],
      "source": [
        "pip install jinaai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJ_rYW1rxdXC"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from smolagents import Tool, ToolCallingAgent, LiteLLMModel\n",
        "\n",
        "\n",
        "class JinaScrapeTool(Tool):\n",
        "    name = \"scrape_page_with_jina_ai\"\n",
        "    description = \"Scrapes a webpage and extracts useful text using Jina AI\"\n",
        "\n",
        "    inputs = {\"url\": {\"type\": \"string\", \"description\": \"The URL to scrape\"}}\n",
        "    output_type = \"string\"\n",
        "\n",
        "    def forward(self, url: str) -> str:\n",
        "        headers = {\"Authorization\": f\"Bearer {\"API_KEY\"}\"}\n",
        "        resp = requests.get(f\"https://r.jina.ai/{url}\", headers=headers)\n",
        "        return resp.text\n",
        "\n",
        "model = LiteLLMModel(model_id=\"gemini/gemini-1.5-flash\", api_key=api_key)\n",
        "\n",
        "\n",
        "agent = ToolCallingAgent(\n",
        "    tools=[JinaScrapeTool()],\n",
        "    model=model\n",
        ")\n",
        "\n",
        "# Now you can run the agent like\n",
        "result = agent.run(\"Scrape the text from https://www.digitalocean.com/blog\")\n",
        "print(result)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
